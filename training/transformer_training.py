from data.dataloading import load_data, ourDataset, train_test_split
from pathlib import Path
import torch
from models.vision_transformer import VisionTransformer
from torch.utils.data import DataLoader
from models.losses.contrastive_losses import contr_loss_simple
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
from scipy.spatial.distance import cdist
import gc
from datetime import datetime


def transformer_train(num_epochs, num_patients, batch_size, hpc=False):
    time_run_started = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Log the device that's being used
    if hpc:
        with open('./logs/device.txt', "w") as f:
            f.write(str(device))

    print(f"Using device {device}")

    # Load data
    cwd = Path.cwd()  # Current working directory
    rel_path = 'data/timeseries_max_all_subjects.hdf5'  # Relative path from project directory, depends on where you store the data
    file_path = (cwd / rel_path).resolve()
    #file_path = (cwd.parent / rel_path).resolve()
    data = load_data(file_path, number_patients=num_patients, normalize=True, verbose=True)

    # data is a dict of numpy arrays, extract the relevant entries
    raw_features = data['raw']
    same_subject = data['same_subject']
    diff_subject = data['diff_subject']
    print(f"Raw features have shape {raw_features.shape}")

    # Train test split with deterministic RNG
    # The seed was generated by calling
    # import secrets; secrets.randbits(128)
    data_split = train_test_split(data, perc=.75, seed=251668716030294078557169461317962359616)

    same_subject_train = data_split['train']['same_subject']
    same_subject_val = data_split['val']['same_subject']
    diff_subject_train = data_split['train']['diff_subject']
    diff_subject_val = data_split['val']['diff_subject']
    raw_features_train = data_split['train']['raw']
    raw_features_val = data_split['val']['raw']

    # Convert to dataset and dataloader
    dataset_train = ourDataset(raw_features_train, device=device)
    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)
    dataset_val = ourDataset(raw_features_val, device=device)
    dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)

    # Hyperparameters
    # Current values are tuned with initial hyperparameter tuning
    length = raw_features.shape[1]
    d_init = raw_features.shape[2]
    d_model = 10  # 30
    n_hidden = 20  # 15
    # d_model must be divisable by n_head
    n_head = 5  # 5
    n_layers = 2  # 1
    lr = 1e-5
    eps = 0.1  # 3.

    # Instantiate model, optimiser and learning rate scheduler
    model = VisionTransformer(length, d_init, d_model, n_hidden, n_head, n_layers, device)
    optimizer = torch.optim.SGD(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5)

    # Testing model output
    test_num = min(10, raw_features.shape[0])
    output = model(raw_features[:test_num].to(device))
    print(f'Tested successfully. Model output has shape {output.shape}')

    # Set up for logging training metrics
    losses = []

    # Training loop
    start_time = time.time()
    pbar = tqdm(range(num_epochs))
    for _ in pbar:
        avg_loss = []  # average loss across batches
        avg_gn = []    # average gradient norm across batches
        # iterate over all data
        for (d, batch_idx) in dataloader_train:
            batch_idx = batch_idx.detach().numpy()
            # get submatrices of same and diff
            same = torch.tensor(same_subject_train[batch_idx[:, None], batch_idx[None, :]]).to(device)
            diff = torch.tensor(diff_subject_train[batch_idx[:, None], batch_idx[None, :]]).to(device)
            # pass through model
            output = model.forward(d)
            # Compute the loss value
            # Currently uses the 'simple' contrastive loss!
            loss = contr_loss_simple(output, same, diff, eps)
            # zero the parameter gradients
            optimizer.zero_grad()
            # Compute the gradients
            loss.backward()
            # Gradient clipping
            gn = torch.nn.utils.clip_grad_norm_(model.parameters(), 100.)
            # Take the optimisation step
            optimizer.step()

            # Remember loss and gradient norm per batch
            avg_loss.append(loss.detach().item())
            avg_gn.append(gn.detach().item())

        # Evaluate model on validation set
        #with torch.no_grad():
        #    avg_loss = []  # We hope this approximates the true loss well but likely misses lots of interactions
        #    for (d, batch_idx) in dataloader_val:
        #        batch_idx = batch_idx.detach().numpy()
        #        same = torch.tensor(same_subject[batch_idx[:, None], batch_idx[None, :]]).to(device)
        #        diff = torch.tensor(diff_subject[batch_idx[:, None], batch_idx[None, :]]).to(device)
        #        output = model.forward(d)
        #        loss = contr_loss_simple(output, same, diff, eps)
        #        avg_loss.append(loss.detach().item())

        #    val_loss = np.array(avg_loss).mean()

        # Update learning rate
        #scheduler.step(val_loss)

        # Update progress bar
        description = (
                        f'Loss {np.array(avg_loss).mean():.2f} | '  
                        f'grad norm {np.array(avg_gn).mean():.2f} | '
                        f'learning rate {optimizer.param_groups[0]["lr"]:.9f}'
        )
        pbar.set_description(description)

        # Logging
        losses.append(np.array(avg_loss).mean())

    end_time = time.time()

    print(f"Training loop ({num_epochs} epochs) executed in {end_time-start_time:.2f}s, or {(end_time-start_time)/num_epochs:.2f}s per epoch.")

    # Save losses to txt file
    filename = f"./logs/loss_{time_run_started}.txt"
    with open(filename, "w") as f:
        np.savetxt(f, np.array(losses))

    filename = f"./logs/loss_{time_run_started}.png"
    # Plot losses and save to figure
    plt.plot(losses)
    plt.title('Losses (averaged over batches) by epoch')
    if hpc:
        plt.savefig(filename)
        plt.close()
    else:
        plt.show()


    print('Evaluating model performance:')
    # Evaluate model performance on training set
    # Pass through model
    output_train = []
    index_train = []
    for it, (d, batch_idx) in enumerate(dataloader_train):
        output = model.forward(d)
        output_train.append(output.detach().cpu().numpy())
        index_train.append(batch_idx.detach().cpu().numpy())
    output_train = np.vstack(output_train)
    index_train = np.hstack(index_train)

    dist_train = cdist(output_train, output_train)
    # get submatrices of same and diff
    same_train_true = same_subject_train[index_train[:, None], index_train[None, :]]
    diff_train_true = diff_subject_train[index_train[:, None], index_train[None, :]]

    # Evaluation 0: mean / median plot;
    # We want the distance for different to be very different from distance for same
    sames = dist_train[same_train_true]
    diffs = dist_train[diff_train_true]
    plt.hist(sames, bins=100, density=True, alpha=.5)
    plt.hist(diffs, bins=100, density=True, alpha=.5)
    plt.xlabel("Distance on training data")
    plt.legend(["Same subject", "Different subject"])
    plt.title(
        f"Histogram of training set\nDifference of medians: {np.median(sames) - np.median(diffs):.2f}\nDifference of means: {np.mean(sames) - np.mean(diffs):.2f}")
    plt.savefig('./figures/histogram_train.png', bbox_inches='tight')
    plt.close()

    # Evaluation 1: we compute the accuracy of the same/diff classification
    threshold = eps  # REQUIRES LOTS OF TUNING
    same_train_pred = (dist_train <= threshold)  # True if above threshold
    diff_train_pred = (dist_train > threshold)

    accuracy_same = np.sum((same_train_pred == same_train_true) & (same_train_true == True)) / np.sum(same_train_true)
    accuracy_diff = np.sum((diff_train_true == diff_train_pred) & (diff_train_true == True)) / np.sum(diff_train_true)
    print(f'Training set: accuracy on same: {accuracy_same:.4f}')
    print(f'Training set: accuracy on different: {accuracy_diff:.4f}')


    # Evaluate model performance on testing set
    # Pass through model
    output_val = []
    index_val = []
    for it, (d, batch_idx) in enumerate(dataloader_val):
        output = model.forward(d)
        output_val.append(output.detach().cpu().numpy())
        index_val.append(batch_idx.detach().cpu().numpy())
    output_val = np.vstack(output_val)
    index_val = np.hstack(index_val)

    dist_val = cdist(output_val, output_val)
    # get submatrices of same and diff
    same_val_true = same_subject_val[index_val[:, None], index_val[None, :]]
    diff_val_true = diff_subject_val[index_val[:, None], index_val[None, :]]

    # Evaluation 0: mean / median plot;
    # We want the distance for different to be very different from distance for same
    sames = dist_val[same_val_true]
    diffs = dist_val[diff_val_true]
    plt.hist(sames, bins=100, density=True, alpha=.5)
    plt.hist(diffs, bins=100, density=True, alpha=.5)
    plt.xlabel("Distance on validation data")
    plt.legend(["Same subject", "Different subject"])
    plt.title(
        f"Histogram of test set\nDifference of medians: {np.median(sames) - np.median(diffs):.2f}\nDifference of means: {np.mean(sames) - np.mean(diffs):.2f}")
    plt.savefig('./figures/histogram_val.png', bbox_inches='tight')
    plt.close()

    # Evaluation 1: we compute the accuracy of the same/diff classification
    threshold = eps  # REQUIRES LOTS OF TUNING
    same_val_pred = (dist_val <= threshold)  # True if above threshold
    diff_val_pred = (dist_val > threshold)

    accuracy_same = np.sum((same_val_pred == same_val_true) & (same_val_true == True)) / np.sum(same_val_true)
    accuracy_diff = np.sum((diff_val_true == diff_val_pred) & (diff_val_true == True)) / np.sum(diff_val_true)
    print(f'Testing set:  accuracy on same: {accuracy_same:.4f}')
    print(f'Testing set:  accuracy on different: {accuracy_diff:.4f}')

    # Print estimated density of the output for training and testing set
    fig, ax = plt.subplots(1, 1)
    sns.kdeplot(data=output_train, ax=ax, palette=['blue'], label='Training')
    sns.kdeplot(data=output_val, ax=ax, palette=['red'], label='Validation')
    plt.title('Approximate density of model output')
    plt.legend()
    plt.savefig('./figures/model_density.png', bbox_inches='tight')
    plt.close()

    # Garbage collection
    del dataset_val, dataloader_val, dataset_train, dataloader_train
    gc.collect()

